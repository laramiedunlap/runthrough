{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in Data from csv --> save the master_loan_tape csv from INTRALINKS into the `raw_data` folder to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.listdir('raw_data/'):\n",
    "    print('Download master_loan_tape.csv from Intralinks and save it in the raw_data folder')\n",
    "\n",
    "else:\n",
    "    loan_data = pd.read_csv(\"raw_data/master_loan_tape.csv\")\n",
    "    # format date columns to datetime data types\n",
    "    date_cols = [c for c in loan_data.columns if str(c)[-2:]=='Dt']\n",
    "    for col in date_cols:\n",
    "        loan_data[col] = pd.to_datetime(loan_data[col])\n",
    "\n",
    "    # Take a look at the top of the dataframe\n",
    "    loan_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the data frame to only 21+ year maturity loans\n",
    "data_slice = loan_data[loan_data['MatBucket']=='21+']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use pool.py to organize cohorts --> loans are split into yyyy.mm cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pooler import pool\n",
    "\n",
    "# Define a function to create static pools of Loans from the DataFrame\n",
    "def create_pooler(in_df:pd.DataFrame)-> pool.Pooler:\n",
    "    temp = in_df.set_index('GP')\n",
    "    temp = temp.to_dict()\n",
    "    loans_dict = {}\n",
    "    for gp in temp['NoteDt'].keys():\n",
    "        loans_dict[str(gp)] = pool.Loan(gp, pd.to_datetime(temp['NoteDt'][gp]))\n",
    "        loans_dict[str(gp)].maturity_dt = temp['MaturityDt'][gp]\n",
    "        loans_dict[str(gp)].maturity_mths_qty = temp['MaturityMthsQty'][gp]\n",
    "        loans_dict[str(gp)].default_dt = temp['DefaultDt'][gp]\n",
    "        loans_dict[str(gp)].default_mths_qty = temp['DefaultMthsQty'][gp]\n",
    "        loans_dict[str(gp)].prepay_dt = temp['PrepayDt'][gp]\n",
    "        loans_dict[str(gp)].prepay_mths_qty = temp['PrepayMthsQty'][gp]\n",
    "\n",
    "    return pool.Pooler(loans_dict)\n",
    "\n",
    "my_pooler = create_pooler(data_slice)\n",
    "my_pooler.build_triangles_counts()\n",
    "\n",
    "pool_dict = {}\n",
    "for k, v in my_pooler.triangles.items():\n",
    "    pool_dict[k] = dict(outstanding=v[0], prepayments=v[1], defaults=v[2])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert Pool dictionaries into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pool Dataframe\n",
    "df_pool = pd.DataFrame.from_dict( pool_dict, orient='index')\n",
    "df_pool.index = [float(e) for e in df_pool.index.to_list()]\n",
    "df_pool = df_pool.sort_index()\n",
    "# Show the dataframe here\n",
    "df_pool.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format array lengths\n",
    "max_row_length = df_pool.shape[0]\n",
    "count = -1\n",
    "for i, row in df_pool.iterrows():\n",
    "    count+=1\n",
    "    for col in df_pool.columns:\n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        #Method 1: This line will simply truncate the array to the right length:\n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        # df_pool.at[i,col] = row[col][:(max_row_length-count)]\n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        #Method 2: Pad arrays with NaNs --> this will truncate the array then fill it back in with NaNs\n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        arr = row[col][:(max_row_length-count)].astype(float)\n",
    "        padded_arr = np.pad(arr, (0, max_row_length - (max_row_length-count) ), mode='constant', constant_values=np.nan)\n",
    "        df_pool.at[i,col] = padded_arr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Group into Annual cohorts and calculate SMM and CPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we start abstracting away from the Data --> you're now looking at Annual Cohorts grouped together\n",
    "df_pool['Year'] = df_pool.index.astype(int)\n",
    "year_grouped = df_pool.groupby('Year')\n",
    "year_grouped = year_grouped.agg(np.nansum)\n",
    "year_grouped['smm'] = (year_grouped['prepayments']+year_grouped['defaults'])/year_grouped['outstanding']\n",
    "year_grouped['cpr'] = (1-(1-year_grouped['smm'])**12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the Yearly cohorts data from Months on Book to Year on Book  \n",
    "`[i,...........,n=MoB] ---> applymap(aggregate_method)`  \n",
    " \n",
    "`[[i,...]`  \n",
    "`[i,...]`  \n",
    "`[i,...]`  \n",
    "`[i,...]`  \n",
    "`[i,...]...n_years=YoB]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_annual_sums(in_arr):\n",
    "    n_years = len(in_arr) // 12\n",
    "    arr_2d = in_arr[:n_years*12].reshape(n_years,12)\n",
    "    return np.nansum(arr_2d,axis=1)\n",
    "\n",
    "def aggregate_annual_averages(in_arr):\n",
    "    n_years = len(in_arr) // 12\n",
    "    arr_2d = in_arr[:n_years*12].reshape(n_years,12)\n",
    "    return np.nanmean(arr_2d,axis=1)\n",
    "\n",
    "arr = year_grouped[['cpr']]\n",
    "cpr_heat = arr.applymap(aggregate_annual_averages).to_dict()\n",
    "cpr_heat = cpr_heat['cpr']\n",
    "\n",
    "\n",
    "cpr_heat = pd.DataFrame.from_dict(cpr_heat, orient='index')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get Line Plots (or just the data for line plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt --> \n",
    "cumsum = np.nancumsum(cpr_heat, axis=1)\n",
    "lifetime_avg= pd.DataFrame(cumsum/np.arange(1,cpr_heat.shape[1]+1), columns=cpr_heat.columns, index=cpr_heat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lifetime_averages(cpr_df:pd.DataFrame)-> pd.DataFrame:\n",
    "    # get the cumulative sum of each row WHILE ignoring NaN values (otherwise the denominator is off)\n",
    "    cumulative_sum = np.nancumsum(cpr_df.values, axis=1)\n",
    "    # compute the number of non-NaN values in each row\n",
    "    num_non_nan = (~np.isnan(cpr_df.values)).cumsum(axis=1)\n",
    "    # get ROW-WISE average up until the first NaN value is encountered\n",
    "    row_avg = np.where(np.isnan(cpr_df), np.nan, cumulative_sum / num_non_nan)\n",
    "    # create new dataframe with row-wise averages\n",
    "    lifetime_df = pd.DataFrame(row_avg, columns=cpr_df.columns, index=cpr_df.index)\n",
    "    return lifetime_df\n",
    "\n",
    "lifetime_cprs = create_lifetime_averages(cpr_heat)\n",
    "\n",
    "lifetime_cprs.fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(lifetime_cprs.transpose(), line_shape= 'spline', title=\"Lifetime Average CPR by Year from Origination\", markers=True)\n",
    "fig.update_layout(yaxis_title='CPR', xaxis_title= 'Year from Origination', yaxis=dict(tickformat='0.0%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
